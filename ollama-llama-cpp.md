# LLM Orchestration in Non-Python

## Quick Hit

- Have Ollama + llama.cpp compiled from source on my workstation.
- Set a few breakpoints where can see the orchestration happen.

## Acknowledgements

Yes, I know this road goes through Python.

